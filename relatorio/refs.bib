@article{goodfellow_generative_2014,
  added-at = {2017-01-09T13:57:26.000+0100},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  biburl = {https://www.bibsonomy.org/bibtex/26ac35c50dee39ad973298799a489b95a/yourwelcome},
  interhash = {2f4fdea569fc1ba2057a9af75bb95bc4},
  intrahash = {6ac35c50dee39ad973298799a489b95a},
  keywords = {Learning, Machine deep generative learning learning, model, unsupervised},
  month = jun,
  timestamp = {2017-01-09T14:01:11.000+0100},
  title = {Generative {Adversarial} {Networks}},
  url = {https://arxiv.org/abs/1406.2661},
  urldate = {2017-01-08},
  year = 2014,
  journal = {Communications of the ACM - October 2020}
}

@misc{dolhansky2019deepfake,
      title={The Deepfake Detection Challenge (DFDC) Preview Dataset}, 
      author={Brian Dolhansky and Russ Howes and Ben Pflaum and Nicole Baram and Cristian Canton Ferrer},
      year={2019},
      eprint={1910.08854},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{violajones04,
  added-at = {2009-09-10T14:36:22.000+0200},
  address = {Hingham, MA, USA},
  author = {Viola, Paul and Jones, Michael J.},
  biburl = {https://www.bibsonomy.org/bibtex/224039942471b72c12f8c75bb9878ca80/gregoryy},
  citeulike-article-id = {942195},
  doi = {10.1023/B:VISI.0000013087.49260.fb},
  interhash = {63e4744aaf116dd7664372ce94392a09},
  intrahash = {24039942471b72c12f8c75bb9878ca80},
  issn = {0920-5691},
  journal = {International Journal of Computer Vision},
  keywords = {boosting, face\_detection},
  month = May,
  number = 2,
  pages = {137--154},
  posted-at = {2008-07-23 16:24:33},
  priority = {2},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2009-09-10T14:36:48.000+0200},
  title = {Robust Real-Time Face Detection},
  url = {http://portal.acm.org/citation.cfm?id=966458},
  volume = 57,
  year = 2004
}




@article{journals/corr/abs-1809-00888,
  added-at = {2018-10-05T00:00:00.000+0200},
  author = {Afchar, Darius and Nozick, Vincent and Yamagishi, Junichi and Echizen, Isao},
  biburl = {https://www.bibsonomy.org/bibtex/20b457b6cff3a7f2c863297c2e9b65357/dblp},
  ee = {http://arxiv.org/abs/1809.00888},
  interhash = {81f7078f9ec3da914560612b04b024a8},
  intrahash = {0b457b6cff3a7f2c863297c2e9b65357},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-10-09T11:38:16.000+0200},
  title = {MesoNet: a Compact Facial Video Forgery Detection Network.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1809.html#abs-1809-00888},
  volume = {abs/1809.00888},
  year = 2018
}

@misc{durall2019unmasking,
    title={Unmasking DeepFakes with simple Features},
    author={Ricard Durall and Margret Keuper and Franz-Josef Pfreundt and Janis Keuper},
    year={2019},
    eprint={1911.00686},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{journals/tifs/CarvalhoRAPR13,
  added-at = {2020-08-06T00:00:00.000+0200},
  author = {de Carvalho, Tiago Jose and Riess, Christian and Angelopoulou, Elli and Pedrini, Hélio and de Rezende Rocha, Anderson},
  biburl = {https://www.bibsonomy.org/bibtex/2a15d259a8d7967e10fe834fe8282bf46/dblp},
  ee = {https://doi.org/10.1109/TIFS.2013.2265677},
  interhash = {afcc1d3c1479f87557aeb431dd329bb4},
  intrahash = {a15d259a8d7967e10fe834fe8282bf46},
  journal = {IEEE Trans. Inf. Forensics Secur.},
  keywords = {dblp},
  number = 7,
  pages = {1182-1194},
  timestamp = {2020-08-07T11:48:24.000+0200},
  title = {Exposing Digital Image Forgeries by Illumination Color Classification.},
  url = {http://dblp.uni-trier.de/db/journals/tifs/tifs8.html#CarvalhoRAPR13},
  volume = 8,
  year = 2013
}

@article{journals/corr/abs-1806-02877,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Li, Yuezun and Chang, Ming-Ching and Lyu, Siwei},
  biburl = {https://www.bibsonomy.org/bibtex/2dd50e600e75fa27a7b18bfc16a23b029/dblp},
  ee = {http://arxiv.org/abs/1806.02877},
  interhash = {6c0076dd43b1ff0d74cdccc1120e1eaa},
  intrahash = {dd50e600e75fa27a7b18bfc16a23b029},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T14:38:19.000+0200},
  title = {In Ictu Oculi: Exposing AI Generated Fake Face Videos by Detecting Eye Blinking.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1806.html#abs-1806-02877},
  volume = {abs/1806.02877},
  year = 2018
}

@misc{Authors06,
 author = {Authors},
 title = {The frobnicatable foo filter},
 note = {ECCV06 submission ID 324. Supplied as additional material {\tt eccv06.pdf}},
 year = 2006
}

@misc{Authors06b,
 author = {Authors},
 title = {Frobnication tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2006
}

@article{Alpher02,
author = {A. Alpher},
title = {Frobnication},
journal = {Journal of Foo},
volume = 12, 
number = 1, 
pages = {234--778}, 
year = 2002
}

@article{Alpher03,
author = {A. Alpher and J.~P.~N. Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13, 
number = 1, 
pages = {234--778}, 
year = 2003
}

@article{Alpher04,
author = {A. Alpher and J.~P.~N. Fotheringham-Smythe and G. Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14, 
number = 1, 
pages = {234--778}, 
year = 2004
}

@article{Mermin89,
author = {N. David Mermin},
title = {What's wrong with these equations?},
journal = {Physics Today},
year = 1989,
month = oct,
note = {\small\url{http://www.cvpr.org/doc/mermin.pdf}}
}

@Book{Hartley00,
  author       = "Hartley, R.~I. and Zisserman, A.",
  title        = "Multiple View Geometry in Computer Vision",
  year         = "2000",
  publisher    = "Cambridge University Press, ISBN: 0521623049",
}

@InProceedings{Scharstein1,
author="Scharstein, Daniel
and Hirschm{\"u}ller, Heiko
and Kitajima, York
and Krathwohl, Greg
and Ne{\v{s}}i{\'{c}}, Nera
and Wang, Xi
and Westling, Porter",
editor="Jiang, Xiaoyi
and Hornegger, Joachim
and Koch, Reinhard",
title="High-Resolution Stereo Datasets with Subpixel-Accurate Ground Truth",
booktitle="Pattern Recognition",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="31--42",
abstract="We present a structured lighting system for creating high-resolution stereo datasets of static indoor scenes with highly accurate ground-truth disparities. The system includes novel techniques for efficient 2D subpixel correspondence search and self-calibration of cameras and projectors with modeling of lens distortion. Combining disparity estimates from multiple projector positions we are able to achieve a disparity accuracy of 0.2 pixels on most observed surfaces, including in half-occluded regions. We contribute 33 new 6-megapixel datasets obtained with our system and demonstrate that they present new challenges for the next generation of stereo algorithms.",
isbn="978-3-319-11752-2",
note = {\small\url{https://www.cs.middlebury.edu/~schar/papers/datasets-gcpr2014.pdf}}
}

@article{Hirschmuller1,
author = {Heiko Hirschmuller},
title = {Stereo Processing by Semi-Global Matching and Mutual Information},
year = 2014,
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence },
note = {\small\url{https://core.ac.uk/download/pdf/11134866.pdf}}
}

@article{DongboMin1,
author = {"Dongbo Min and Sunghwan Choi and Jiangbo Lu and  Bumsub Ham and Kwanghoon Sohn and Minh N. Do"},
title = {Fast Global Image Smoothing Based on Weighted Least Squares},
year = 2014,
journal = {IEEE TRANSACTION ON IMAGE PROCESSING},
note = {\small\url{http://publish.illinois.edu/visual-modeling-and-analytics/files/2014/10/FGS-TIP.pdf}}
}

@INPROCEEDINGS{Flann,
    author = {Marius Muja and David G. Lowe},
    title = {Fast approximate nearest neighbors with automatic algorithm configuration},
    booktitle = {In VISAPP International Conference on Computer Vision Theory and Applications},
    year = {2009},
    pages = {331--340}
}

@InProceedings{Claus05,
  author       = "Claus, D. and Fitzgibbon, A.~W.",
  title        = "A Rational Function Lens Distortion Model for General
                 Cameras",
  booktitle    = "Proc. CVPR",
  year         = "2005",
  pages        = "213--219",
}

@InProceedings{Zhang96,
  author =	 "Z. Zhang",
  title =	 "On the Epipolar Geometry Between Two Images With
                  Lens Distortion",
  booktitle =	 "Proc. ICPR",
  year =	 "1996",
  pages =	 "407--411",
}

@INPROCEEDINGS{Sift,
  author={D. G. {Lowe}},
  booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision}, 
  title={Object recognition from local scale-invariant features}, 
  year={1999},
  volume={2},
  number={},
  pages={1150-1157 vol.2},
  doi={10.1109/ICCV.1999.790410}
}

@InProceedings{Fitzgibbon01,
  author       = "Fitzgibbon, A.~W.",
  title        = "Simultaneous Linear Estimation of Multiple View
                 Geometry and Lens Distortion",
  booktitle    = "Proc. CVPR",
  year         = "2001"
}

@article{Brown71,
author = {D.~C. Brown},
title = {Close-range camera calibration},
journal = {Photogrammetric Eng.},
volume = 37,
number = 8,
pages = {855--866}, 
year = 1971
}

@article{Devernay01,
author = {F. Devernay and O. Faugeras},
title = {Straight lines have to be straight},
journal = {MVA},
volume = 13,
pages = {14--24}, 
year = 2001
}

@article{Swaminathan00,
author = {R. Swaminathan and S. Nayar},
title = {Nonmetric calibration of wide-angle lenses and polycameras},
journal = {IEEE T-PAMI},
volume = 22,
number = 10,
pages = {1172--1178}, 
year = 2000
}

@InProceedings{Tsai86,
  author =	 "Tsai, Y.~R.",
  title =	 "An Efficient and Accurate Camera Calibration
                  Technique for {3D} Machine Vision",
  booktitle =	 "Proc. CVPR",
  year =	 "1986",
}

@inproceedings{Silberman:ECCV12,
  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title     = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year      = {2012}
}

@INPROCEEDINGS{6247999,
author={X. Ren and L. Bo and D. Fox},
booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
title={RGB-(D) scene labeling: Features and algorithms},
year={2012},
volume={},
number={},
pages={2759-2766},
keywords={image colour analysis;image segmentation;trees (mathematics);Microsoft Kinect;RGB-(D) scene labeling;RGB-D features;RGB-D perception;contextual modeling;indoor scenes;kernel descriptors;local similarities;outdoor scenes;patch descriptors;scene labeling research;segmentation tree;superpixel MRF;Accuracy;Context modeling;Image color analysis;Image segmentation;Kernel;Labeling;Vegetation},
doi={10.1109/CVPR.2012.6247999},
ISSN={1063-6919},
month={June},}

@INPROCEEDINGS{7298863,
author={J. Rock and T. Gupta and J. Thorsen and J. Gwak and D. Shin and D. Hoiem},
booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Completing 3D object shape from one depth image},
year={2015},
volume={},
number={},
pages={2484-2493},
keywords={computer graphics;image matching;image reconstruction;shape recognition;3D model reconstruction;3D object shape;depth image;exemplar-based approach;view-based matching;Approximation methods;Deformable models;Image reconstruction;Shape;Solid modeling;Three-dimensional displays;Training},
doi={10.1109/CVPR.2015.7298863},
ISSN={1063-6919},
month={June},}


@INPROCEEDINGS{8099511,
author={S. Song and F. Yu and A. Zeng and A. X. Chang and M. Savva and T. Funkhouser},
booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Semantic Scene Completion from a Single Depth Image},
year={2017},
volume={},
number={},
pages={190-198},
keywords={image representation;learning (artificial intelligence);3D context learning;complete 3D voxel representation;dilation-based 3D context module;end-to-end 3D convolutional network;semantic labels;semantic scene completion network;single depth image;single-view depth map observation;volumetric occupancy;Convolution;Geometry;Semantics;Shape;Solid modeling;Three-dimensional displays},
doi={10.1109/CVPR.2017.28},
ISSN={1063-6919},
month={July},}


@article{DBLP:journals/corr/abs-1802-04735,
  author    = {Andre Bernardes Soares Guedes and
               Te{\'{o}}filo Em{\'{\i}}dio de Campos and
               Adrian Hilton},
  title     = {Semantic Scene Completion Combining Colour and Depth: preliminary
               experiments},
  journal   = {CoRR},
  volume    = {abs/1802.04735},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.04735},
  archivePrefix = {arXiv},
  eprint    = {1802.04735},
  timestamp = {Thu, 01 Mar 2018 15:00:45 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1802-04735},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-1804-03550,
  author    = {Martin Garbade and
               Johann Sawatzky and
               Alexander Richard and
               Juergen Gall},
  title     = {Two Stream 3D Semantic Scene Completion},
  journal   = {CoRR},
  volume    = {abs/1804.03550},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.03550},
  archivePrefix = {arXiv},
  eprint    = {1804.03550},
  timestamp = {Tue, 01 May 2018 19:46:29 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1804-03550},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{wong_understanding_2016,
	title = {Understanding data augmentation for classification: when to warp?},
	shorttitle = {Understanding data augmentation for classification},
	pages = {1--6},
	booktitle = {Digital Image Computing: Techniques and Applications ({DICTA}), 2016 International Conference on},
	publisher = {{IEEE}},
	author = {Wong, Sebastien C. and Gatt, Adam and Stamatescu, Victor and {McDonnell}, Mark D.},
	date = {2016},
	file = {1609.08764.pdf:/home/adn/.zotero/zotero/zl50calj.default/zotero/storage/GNMSCEFA/1609.08764.pdf:application/pdf}
}



@article{cehovin_visual_2016,
	title = {Visual {Object} {Tracking} {Performance} {Measures} {Revisited}},
	volume = {25},
	issn = {1057-7149},
	doi = {10.1109/TIP.2016.2520370},
	number = {3},
	journal = {IEEE Transactions on Image Processing},
	author = {Čehovin, L. and Leonardis, A. and Kristan, M.},
	month = mar,
	year = {2016},
	keywords = {Current measurement, experimental evaluation, object tracking, Object tracking, performance evaluation, Performance evaluation, performance measures, Robustness, Target tracking, visual object tracking, Visual object tracking, visual object tracking performance measures, Visualization},
	pages = {1261--1274},
	file = {1502.05803.pdf:/home/adn/Zotero/storage/AJ2GRKSK/1502.05803.pdf:application/pdf}
}

@inproceedings{van_der_merwe_square-root_2001,
	title = {The square-root unscented {Kalman} filter for state and parameter-estimation},
	volume = {6},
	isbn = {978-0-7803-7041-8},
	url = {http://ieeexplore.ieee.org/document/940586/},
	doi = {10.1109/ICASSP.2001.940586},
	language = {en},
	urldate = {2018-06-09},
	publisher = {IEEE},
	author = {Van der Merwe, R. and Wan, E.A.},
	year = {2001},
	pages = {3461--3464},
	file = {Van der Merwe e Wan - 2001 - The square-root unscented Kalman filter for state .pdf:/home/adn/Zotero/storage/SWBTKIZF/Van der Merwe e Wan - 2001 - The square-root unscented Kalman filter for state .pdf:application/pdf}
}

@article{julier_new_nodate,
	title = {A {New} {Extension} of the {Kalman} {Filter} to {Nonlinear} {Systems}},
	abstract = {The Kalman ﬁlter(KF) is one of the most widely used methods for tracking and estimation due to its simplicity, optimality, tractability and robustness. However, the application of the KF to nonlinear systems can be diﬃcult. The most common approach is to use the Extended Kalman Filter (EKF) which simply linearises all nonlinear models so that the traditional linear Kalman ﬁlter can be applied. Although the EKF (in its many forms) is a widely used ﬁltering strategy, over thirty years of experience with it has led to a general consensus within the tracking and control community that it is diﬃcult to implement, diﬃcult to tune, and only reliable for systems which are almost linear on the time scale of the update intervals.},
	language = {en},
	author = {Julier, Simon J and Uhlmann, Jeﬀrey K},
	pages = {12},
	file = {Julier e Uhlmann - A New Extension of the Kalman Filter to Nonlinear .pdf:/home/adn/Zotero/storage/XUHXR322/Julier e Uhlmann - A New Extension of the Kalman Filter to Nonlinear .pdf:application/pdf}
}

@article{kwon_visual_2018,
	title = {Visual tracking based on edge field with object proposal association},
	volume = {69},
	issn = {02628856},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885617301804},
	doi = {10.1016/j.imavis.2017.11.004},
	abstract = {In this paper, we present a novel tracking system based on edge-based object proposal and data association called object proposal association. Our object proposal method accurately detects and localizes objects in an image by searching for object-like regions, with the assumption that an object is represented by a closed boundary. To search for closed boundaries in an image, we present a new Edge Fields (EFs) technique. Using this technique, our method can extract high-quality edges and can obtain accurate boundaries from the image. The EFs technique consists of blurring and thresholding steps, where the former helps extract high-quality edges and the latter prevents the method from losing image details while blurring. After the method extracts object-like regions, we associate the regions in the previous frame with those in the current frame. For this purpose, using the Markov chain Monte Carlo data association (MCMCDA) algorithm, we can ﬁnd pairs of similar regions across two frames. Experimental results demonstrate that our object proposal method is competitive with state-of-the-art object proposal methods on the PASCAL VOC 2007 dataset. Our tracking method is also competitive with state-of-the-art tracking methods on Object Tracking Benchmark dataset.},
	language = {en},
	urldate = {2018-06-09},
	journal = {Image and Vision Computing},
	author = {Kwon, Junseok and Lee, Hansung},
	month = jan,
	year = {2018},
	pages = {22--32},
	file = {Kwon e Lee - 2018 - Visual tracking based on edge field with object pr.pdf:/home/adn/Zotero/storage/ZT3XBRQM/Kwon e Lee - 2018 - Visual tracking based on edge field with object pr.pdf:application/pdf}
}

@article{dubuisson_survey_2016,
	title = {A survey of datasets for visual tracking},
	volume = {27},
	issn = {0932-8092, 1432-1769},
	url = {http://link.springer.com/10.1007/s00138-015-0713-y},
	doi = {10.1007/s00138-015-0713-y},
	abstract = {For 15 years now, visual tracking has been a very active research area of the computer vision community. But an increasing amount of works can be observed in the last ﬁve years. This has led to the development of numerous algorithms that can deal with more and more complex video sequences. Each of them has its own strengths and weaknesses. That is the reason why it becomes necessary to compare those algorithms. For this purpose, some datasets dedicated to visual tracking as well as, sometimes, their ground truth annotation ﬁles are regularly made publicly available by researchers. However, each dataset has its own speciﬁcities and is sometimes dedicated to test the ability of some algorithms to tackle only one or a few speciﬁc visual tracking subproblems. This article provides an overview of some of the datasets that are most used by the visual tracking community, but also of others that address speciﬁc tasks. We also propose a cartography of these datasets from a novel perspective, namely that of the difﬁculties the datasets present for visual tracking.},
	language = {en},
	number = {1},
	urldate = {2018-06-09},
	journal = {Machine Vision and Applications},
	author = {Dubuisson, Séverine and Gonzales, Christophe},
	month = jan,
	year = {2016},
	pages = {23--52},
	file = {Dubuisson e Gonzales - 2016 - A survey of datasets for visual tracking.pdf:/home/adn/Zotero/storage/JWIQU73Z/Dubuisson e Gonzales - 2016 - A survey of datasets for visual tracking.pdf:application/pdf}
}

@article{fu_centroid_2012,
	title = {Centroid weighted {Kalman} filter for visual object tracking},
	volume = {45},
	issn = {02632241},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S026322411200005X},
	doi = {10.1016/j.measurement.2012.01.004},
	abstract = {In the visual object tracking, the Kalman ﬁlter presents commonly the state model and observation model uncertainty in the actual performance of Gaussian noise, so it makes the estimation of certain parameters produce errors in the model, and results in decreasing estimation precision. In order to enhance the stability of the Kalman ﬁlter, an algorithm based on centroid weighted Kalman ﬁlter (CWKF) for object tracking is proposed in this paper. The algorithm ﬁrstly uses background subtraction method to detect moving target region, and then uses the Kalman ﬁlter to predict target position, combining centroid weighted method to optimize the predictive state value, ﬁnally updates observation data according to the corrected state value. Tracking experiments show that the algorithm can detect effectively moving objects and at the same time it can quickly and accurately track moving objects with good robustness.},
	language = {en},
	number = {4},
	urldate = {2018-06-09},
	journal = {Measurement},
	author = {Fu, Zhaoxia and Han, Yan},
	month = may,
	year = {2012},
	pages = {650--655},
	file = {Fu e Han - 2012 - Centroid weighted Kalman filter for visual object .pdf:/home/adn/Zotero/storage/NRDXRLUR/Fu e Han - 2012 - Centroid weighted Kalman filter for visual object .pdf:application/pdf}
}

@article{jepson_robust_2001,
	title = {Robust {Online} {Appearance} {Models} for {Visual} {Tracking}},
	volume = {1},
	abstract = {We propose a framework for learning robust, adaptive, appearance models to be used for motion-based tracking of natural objects. The approach involves a mixture of stable image structure, learned over long time courses, along with 2-frame motion information and an outlier process. An online EM-algorithm is used to adapt the appearance model parameters over time. An implementation of this approach is developed for an appearance model based on the ﬁlter responses from a steerable pyramid. This model is used in a motion-based tracking algorithm to provide robustness in the face of image outliers, such as those caused by occlusions. It is also provides the ability to adapt to natural changes in appearance, such as those due to facial expressions or variations in 3D pose. We show experimental results on a variety of natural image sequences of people moving within cluttered environments.},
	language = {en},
	journal = {IEEE Conference on Computer Vision and and Pattern Recognition},
	author = {Jepson, Allan D and Fleet, David J and El-Maraghi, Thomas F},
	year = {2001},
	pages = {415-422},
	file = {Jepson et al. - Robust Online Appearance Models for Visual Trackin.pdf:/home/adn/Zotero/storage/V4BJUWVX/Jepson et al. - Robust Online Appearance Models for Visual Trackin.pdf:application/pdf}
}
@inproceedings{olson_maximum-likelihood_2000,
	title = {Maximum-likelihood template matching},
	volume = {2},
	isbn = {978-0-7695-0662-3},
	url = {http://ieeexplore.ieee.org/document/854735/},
	doi = {10.1109/CVPR.2000.854735},
	language = {en},
	urldate = {2018-06-09},
	publisher = {IEEE Comput. Soc},
	author = {Olson, C.F.},
	year = {2000},
	pages = {52--57},
	file = {Olson - 2000 - Maximum-likelihood template matching.pdf:/home/adn/Zotero/storage/69IIFD2U/Olson - 2000 - Maximum-likelihood template matching.pdf:application/pdf}
}

